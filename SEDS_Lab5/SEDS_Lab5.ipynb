{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG src=\"figures/logo-esi-sba.png\" WIDTH=300 height=\"100\" ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Practical Trainining Series on Software Engineering For Data Science  \n",
    "*By Dr. Belkacem KHALDI (b.khaldi@esi-sba.dz)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Notebook 5: Data Processing & Cleaning for Data Science: Data Ingestion and Wrangling with Pandas\n",
    "\n",
    "The purpose of this [Jupyter Notebook] is to getting you introduced to the Data Processing & Cleaning for Data\n",
    "Science: Data Ingestion and Wrangling with Pandas. It provides a set of practical Training challenges that allow grasping the different concepts presented in the lecture 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1\n",
    "1. Connect to the `chinook.db` sqlite3 database available in the folder data.\n",
    "2. Find the genre names with the longest average song length.\n",
    "\n",
    "`Hint:`\n",
    "join the tables with the genre name and song length and use the SQLite aggregate\n",
    "function for the average along with a GROUP BY clause.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: Ingesting, Wrangling and Analyzing  iTune data\n",
    "\n",
    "You've started a new data science position at the iTune department at Apple Company. \n",
    "The department wants to build, test, and evaluate new machine learning recommendation song models using a different source of data: in Excel file, in a csv file, and in the chinook.db SQLite database. They want you proceed with the data ingsestion and data wrangling procedures to provide a clean dataset to be used later for their machine learning based recommendation songs models.  \n",
    "\n",
    "1. They particlarly asked you to load, clean, and analyze, and then deliver your results to the executive team and president.\n",
    "You should deliver a small summary of your EDA work from pandas and save your cleaned and prepared data as a new Excel file. The data files are `chinook_data.xlsx`, `chinook_data.csv`, and `chinook.db` on the data folder existed within this notebook.\n",
    "\n",
    "`Hint:`\n",
    "1. Follow the procedures in Lecture 5 - Slides: 13-17 - For data ingestion (Data loading from different sources).\n",
    "\n",
    "2. Follow and test the procedures in Lecture 5 - Slides:18-22 - For Basic Exploratory Data Analysis (EDA).\n",
    "\n",
    "3. Follow and test the procedures in Lecture 5 - Slides:23-27 - For Basic Data Cleaning Operations.\n",
    "\n",
    "4. To save your cleaned dataset in an excel file use the pandas built-in method: `pandas.DataFrame.to_excel`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3: Ingesting, Wrangling and Analyzing Bitcoin price data\n",
    "\n",
    "\n",
    "You have just joined a financial company as a new data scientist. The company is  interested in the Bitcon market and you are working with a team that aims to ingest data and then clean, and analyse the final dataset to be used later to build and evaluate machine learning models for Bitcon Price forecasting.\n",
    "\n",
    "The company is working with two datasets coming from two different sources and is only interested in the `BTCUSD` currency: \n",
    "1. One dataset is json file locally existed in the data folder: `bitcoin_price.json`. This file contains data up to `2020-11-27`\n",
    "2. The other uses a real time data flow that comes from yahoo finance api service. The company wants to collect real time data beginning from `2020-11-28` to `2022-10-31`.\n",
    "\n",
    "You are asked to do the required checklist procedures and operations to load, clean, and analyse, and then deliver your results to the executive team with providing a short summaray of your prelimanary EDA work from pandas and save the cleaner dataset as a new csv file. \n",
    "Note that the \n",
    "\n",
    "`Hint:`\n",
    "\n",
    "1. To load a json file into a dataframe use the snipet code below:\n",
    "\n",
    "```python\n",
    "import json\n",
    "\n",
    "with open('<path_to_your_json_file>') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "btc_df_jsn=pd.DataFrame.from_dict(data)\n",
    "```\n",
    "\n",
    "This code uses the `json` built-in python module to open a json file and load it in an object data. Then we use the `from_dict()` pandas method to transform the json data into a DataFrame.\n",
    "\n",
    "2. To get real time data flow from the yahoo finance api sevice we will use the `yfinance` module. \n",
    "    * So, first install the module in your environment using  `conda install yfinance`.\n",
    "    * Then use the code below to get real data. Test with the periode from `2020-01-01` to `2024-10-31`.\n",
    "\n",
    "```python\n",
    "import yfinance as yf\n",
    "\n",
    "btc_yf_df = yf.download('BTC-USD', # The currency we are intersted in\n",
    "                   start='<start_date>', # The starting date\n",
    "                   end='<end_date>', # The starting date\n",
    "                   interval='1d' # The frequency of collecting the data. here 1 day\n",
    "                  )\n",
    "```\n",
    "\n",
    "3. Get a look of the two DataFrames and see what are the common columns and what differ one to another.\n",
    "    * You will notice that the  json DataFrame is indexed numericaly wherease the yahoo DataFrame is indexed by Date. So, you have to uniform the index for both DataFrames. In this case we will change the json DataFrame  index by Date.\n",
    "        1. To do that, first rename the column `time` to `Date` by using the built-in pandas method: `rename()` as follows:\n",
    "        \n",
    "        ```python\n",
    "        rename(columns ={'<old_col_name>':'<new_col_name>'}, inplace = True)\n",
    "         ```\n",
    "         \n",
    "        2. What is the datatype of the new Date column in the json DataFrame?\n",
    "            * You will notice that it is a `datetime64[ns]` datatype, which means the number of seconds since 1-1-1970. To make it date fomat like the yahoo DataFrame, convert the column to a pandas datetime datatype by using the following code: \n",
    "         \n",
    "          ```python\n",
    "              btc_df['<column_name>'] = pd.to_datetime(btc_df['<column_name>'], unit='ms')\n",
    "          ```\n",
    "         \n",
    "        3. To change the index of your dataframe use the `set_index` built-in pandas function:\n",
    "        ```python\n",
    "              set_index('<column_name>', inplace=True)\n",
    "        ```\n",
    "            * The remaining common columns labels in both DataFrames are not uniformed. The json DataFrame uses lowercase strings,  while the yahoo DataFrame uses a first letter world uppercase string.\n",
    "                  1. Change the column labels of the yahoo DataFrame to lowercase strings. Adjust the following code accordingly:\n",
    "             ```python\n",
    "                data_frame.columns= data_frame.columns.str.lower()\n",
    "             ```\n",
    "             \n",
    "4. Concatenate the two dataframe into one dataset.\n",
    "5. Do The basic EDA cheklist procedures on the resulting dataset:\n",
    "   * Do few time series plots: \n",
    "       * open, close, high, low, volume with regards to Date\n",
    "   * Print the correlation matrix.\n",
    "6. Do the General Data Cleaning Checklist operations to see if ther is still cleaning operations to accomplish.\n",
    "    * Most particularly, you will notice a NaN values in both `adj close` and `symbole` columns. What is your suggestion to deal with this missing values given that the company is not interest at all on the `adj close` data. \t\n",
    "7. Save your cleaner dataframe into a csv file.\n",
    "    * Use the `pandas.DataFrame.to_csv` method.\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Solution"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
